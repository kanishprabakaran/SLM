{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84133543-99b7-4afa-a5dc-ea04f2a5bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (0.15.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting trl\n",
      "  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\kanish prabakaran\\appdata\\roaming\\python\\python312\\site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from peft) (0.32.4)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Downloading trl-0.19.0-py3-none-any.whl (375 kB)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.19.0\n"
     ]
    }
   ],
   "source": [
    "pip install peft trl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b24cce43-44df-4578-b02d-1a491cf9b8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.20.1-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (8.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: packaging in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (24.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\kanish prabakaran\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\kanish prabakaran\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.31.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.6-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from pydantic<3->wandb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from pydantic<3->wandb) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\kanish prabakaran\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "Downloading wandb-0.20.1-py3-none-win_amd64.whl (22.5 MB)\n",
      "   ---------------------------------------- 0.0/22.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/22.5 MB 7.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.4/22.5 MB 6.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.4/22.5 MB 6.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.9/22.5 MB 5.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.5/22.5 MB 4.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.0/22.5 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.5 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.0/22.5 MB 3.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 6.6/22.5 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.1/22.5 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 7.6/22.5 MB 3.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.1/22.5 MB 3.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 8.7/22.5 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 9.2/22.5 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 9.4/22.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 10.2/22.5 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 10.5/22.5 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.0/22.5 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 11.5/22.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 12.1/22.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 12.6/22.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 13.1/22.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 13.4/22.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 14.2/22.5 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 14.4/22.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 14.9/22.5 MB 2.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 15.5/22.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 16.0/22.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 16.3/22.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 16.8/22.5 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 17.0/22.5 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 17.6/22.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 17.8/22.5 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 18.1/22.5 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 18.4/22.5 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 18.9/22.5 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 19.1/22.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 19.4/22.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 19.7/22.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 19.9/22.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 20.2/22.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.4/22.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 20.7/22.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.0/22.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.2/22.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.5/22.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.8/22.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.0/22.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.3/22.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.5/22.5 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.31.0-py2.py3-none-any.whl (355 kB)\n",
      "Downloading setproctitle-1.3.6-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, wandb\n",
      "Successfully installed sentry-sdk-2.31.0 setproctitle-1.3.6 wandb-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1057d9f8-51bc-4d19-9a74-673a2bbd421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'messages', 'prompt_id'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_json('nl_sparql_pairs_500.json')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87175f3e-d222-4df1-8ead-645e16d954af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kanish Prabakaran\\wandb\\run-20250624_235115-p6ftcnze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized/runs/p6ftcnze' target=\"_blank\">sleek-disco-1</a></strong> to <a href='https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized' target=\"_blank\">https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized/runs/p6ftcnze' target=\"_blank\">https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized/runs/p6ftcnze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kanishswagup-amrita-vishwa-vidyapeetham/uncategorized/runs/p6ftcnze?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x21ef8e3f7a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4b7ed-c1e7-46f4-991a-3a95a94c014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:2135] 2025-06-25 09:15:10,900 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1812] 2025-06-25 09:15:10,903 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 09:15:10 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: False\n",
      "2025-06-25 09:15:10 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./checkpoint_dir\\runs\\Jun25_09-15-10_LAPTOP-657ABJD1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./checkpoint_dir,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./checkpoint_dir,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=SaveStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2025-06-25 09:15:10 - INFO - __main__ - PEFT parameters LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=8, target_modules={'up_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj', 'down_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:698] 2025-06-25 09:15:12,487 >> loading configuration file config.json from cache at C:\\Users\\Kanish Prabakaran\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\0a67737cc96d2554230f90338b163bc6380a2a85\\config.json\n",
      "[INFO|configuration_utils.py:698] 2025-06-25 09:15:12,806 >> loading configuration file config.json from cache at C:\\Users\\Kanish Prabakaran\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\0a67737cc96d2554230f90338b163bc6380a2a85\\config.json\n",
      "[INFO|configuration_utils.py:770] 2025-06-25 09:15:12,810 >> Model config Phi3Config {\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2025-06-25 09:15:13,152 >> loading weights file model.safetensors from cache at C:\\Users\\Kanish Prabakaran\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\0a67737cc96d2554230f90338b163bc6380a2a85\\model.safetensors.index.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14f678e597148b3be6cfcc59e93d7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783a53ae4c044b5990b2b3e581486baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  38%|###8      | 3.09G/8.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Training config\n",
    "training_config = {\n",
    "    \"bf16\": False,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "}\n",
    "\n",
    "# LoRA config\n",
    "peft_config = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")\n",
    "\n",
    "# Model loading\n",
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Data processing\n",
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"messages\"]\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# Placeholder dataset (replace with your SPARQL dataset)\n",
    "train_dataset = dataset\n",
    "test_dataset = dataset\n",
    "column_names = list(train_dataset.features)\n",
    "\n",
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "processed_test_dataset = test_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to test_sft\",\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_test_dataset,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "# Evaluation\n",
    "tokenizer.padding_side = \"left\"\n",
    "metrics = trainer.evaluate()\n",
    "metrics[\"eval_samples\"] = len(processed_test_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(train_conf.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
